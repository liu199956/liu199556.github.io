<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="异步爬虫 1 asyncio事件循环 123456789101112import asyncio# 生成一个事件循环loop &#x3D; asyncio.get_event_loop()loop.run_untile_complete(任务)asyncio def func(): # 协程函数    passres &#x3D; func() # 协程对象# 执行协程函数创建协程对象，函数内部代码不会被执行，交予事">
<meta property="og:type" content="article">
<meta property="og:title" content="Admin">
<meta property="og:url" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/index.html">
<meta property="og:site_name" content="Admin">
<meta property="og:description" content="异步爬虫 1 asyncio事件循环 123456789101112import asyncio# 生成一个事件循环loop &#x3D; asyncio.get_event_loop()loop.run_untile_complete(任务)asyncio def func(): # 协程函数    passres &#x3D; func() # 协程对象# 执行协程函数创建协程对象，函数内部代码不会被执行，交予事">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20201130160241433.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20220701150552130.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20220701153654535.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805003708180.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805013247183.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805013647300.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805013936878.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805014139441.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805021522176.png">
<meta property="og:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20210806010100962.png">
<meta property="article:published_time" content="2020-12-23T05:33:37.000Z">
<meta property="article:modified_time" content="2022-07-01T07:37:15.532Z">
<meta property="article:author" content="Admin">
<meta property="article:tag" content="爬虫">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/image-20201130160241433.png">

<link rel="canonical" href="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title> | Admin</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Admin" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
	
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Admin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/12/23/%E7%88%AC%E8%99%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Admin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Admin">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
        </h1>

        <div class="post-meta">
		<!-- 设置置顶标志 -->
			
			  <i class="fa fa-thumb-tack"></i>
			  <font color=7D26CD>置顶</font>
			  <span class="post-meta-divider">|</span>
			
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-12-23 13:33:37" itemprop="dateCreated datePublished" datetime="2020-12-23T13:33:37+08:00">2020-12-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-07-01 15:37:15" itemprop="dateModified" datetime="2022-07-01T15:37:15+08:00">2022-07-01</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="异步爬虫"><a href="#异步爬虫" class="headerlink" title="异步爬虫"></a>异步爬虫</h1><p><strong><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20201130160241433.png" alt="爬虫"></strong></p>
<h2 id="1-asyncio"><a href="#1-asyncio" class="headerlink" title="1 asyncio"></a>1 asyncio</h2><p><code>事件循环</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成一个事件循环</span></span><br><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_untile_complete(任务)</span><br><span class="line"></span><br><span class="line">asyncio <span class="function"><span class="keyword">def</span> <span class="title">func</span>():</span> <span class="comment"># 协程函数</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line">res = func() <span class="comment"># 协程对象</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行协程函数创建协程对象，函数内部代码不会被执行，交予事件循环</span></span><br><span class="line">asyncio.run( res )</span><br></pre></td></tr></table></figure>

<p><code>异步可迭代器对象</code></p>
<p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20220701150552130.png" alt="爬虫"></p>
<p><code>异步上下文管理器</code></p>
<p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20220701153654535.png" alt="爬虫"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span>(<span class="params">task</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;i am callback&#x27;</span>, task.result())</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    task.result()</span></span><br><span class="line"><span class="string">        接收特殊函数的返回值</span></span><br><span class="line"><span class="string">        下载成功 www.baidu.com</span></span><br><span class="line"><span class="string">        下载成功 www.jd.com</span></span><br><span class="line"><span class="string">        i am callback www.baidu.com</span></span><br><span class="line"><span class="string">        i am callback www.jd.com</span></span><br><span class="line"><span class="string">        耗时 2.001952648162842</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特殊函数</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_request</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="comment"># time.sleep(2) # 4s多</span></span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载成功&#x27;</span>, url)</span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    <span class="string">&#x27;www.baidu.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;www.jd.com&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tasks = []</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    res = get_request(url)</span><br><span class="line">    task = asyncio.ensure_future(res)  <span class="comment"># 封装一个任务对象</span></span><br><span class="line">    task.add_done_callback(callback)  <span class="comment"># 绑定回调函数</span></span><br><span class="line">    tasks.append(task)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()  <span class="comment"># 创建一个事件循环对象</span></span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks)) <span class="comment"># 开启事件循环</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;耗时&#x27;</span>, time.time() - start)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-多线程异步"><a href="#2-多线程异步" class="headerlink" title="2 多线程异步"></a>2 多线程异步</h2><p>flask_Server</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/lhj&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_lhj</span>():</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;lhj&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/lyh&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_lyh</span>():</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;lyh&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure>

<p>多线程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lhj&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lyh&#x27;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_request</span>(<span class="params">url</span>):</span></span><br><span class="line">    page_test = requests.get(url=url).text</span><br><span class="line">    <span class="built_in">print</span>(page_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pool = Pool(<span class="number">2</span>)</span><br><span class="line">pool.<span class="built_in">map</span>(get_request, urls)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;耗时&#x27;</span>, time.time() - start)</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">lhj</span></span><br><span class="line"><span class="string">lyh</span></span><br><span class="line"><span class="string">耗时 2.0199060440063477</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="3-多任务异步协程"><a href="#3-多任务异步协程" class="headerlink" title="3 多任务异步协程"></a>3 多任务异步协程</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span>(<span class="params">task</span>):</span></span><br><span class="line">    page_text = task.result()</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    parse_data = tree.xpath(<span class="string">&#x27;//li/text()&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(parse_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特殊函数</span></span><br><span class="line"><span class="comment"># 注意：</span></span><br><span class="line"><span class="comment"># 每一个with要加上async（表示异步操作）在每一个阻塞的前面加上await</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_request</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> s:</span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> <span class="keyword">await</span> s.get(url) <span class="keyword">as</span> response:</span><br><span class="line">            page_text = <span class="keyword">await</span> response.text()</span><br><span class="line">            <span class="keyword">return</span> page_text</span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lhj&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lyh&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lxx&#x27;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tasks = []</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    res = get_request(url)</span><br><span class="line">    task = asyncio.ensure_future(res)  <span class="comment"># 封装一个任务对象</span></span><br><span class="line">    task.add_done_callback(callback)  <span class="comment"># 绑定回调函数</span></span><br><span class="line">    tasks.append(task)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()  <span class="comment"># 创建一个事件循环对象</span></span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;耗时&#x27;</span>, time.time() - start)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;三个请求耗时2s</span></span><br><span class="line"><span class="string">[&#x27;i am superman &#x27;, &#x27;i am hero &#x27;, &#x27;i am super &#x27;]</span></span><br><span class="line"><span class="string">[&#x27;i am superman &#x27;, &#x27;i am hero &#x27;, &#x27;i am super &#x27;]</span></span><br><span class="line"><span class="string">[&#x27;i am superman &#x27;, &#x27;i am hero &#x27;, &#x27;i am super &#x27;]</span></span><br><span class="line"><span class="string">耗时 2.015962600708008</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>flask_Server</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> flask <span class="keyword">import</span> Flask, render_template</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/lhj&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_lhj</span>():</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;test.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/lyh&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_lyh</span>():</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;test.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/lxx&#x27;</span></span>)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index_lxx</span>():</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> render_template(<span class="string">&#x27;test.html&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    app.run()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>test.html</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="meta-keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span> <span class="attr">lang</span>=<span class="string">&quot;en&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">meta</span> <span class="attr">charset</span>=<span class="string">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span>Title<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.bootcdn.net/ajax/libs/jquery/3.4.1/jquery.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">&quot;https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css&quot;</span> <span class="attr">rel</span>=<span class="string">&quot;stylesheet&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">&quot;https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">h2</span>&gt;</span>hello<span class="tag">&lt;/<span class="name">h2</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>i am superman <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>i am hero <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span>&gt;</span>i am super <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="4-破解验证码登录"><a href="#4-破解验证码登录" class="headerlink" title="4 破解验证码登录"></a>4 <em>破解验证码登录</em></h2><p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805003708180.png" alt="爬虫"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">- <span class="number">1</span>对图片验证码进行捕获识别存储到本地</span><br><span class="line">- <span class="number">2</span>使用第三方平台解析验证码中的数字</span><br><span class="line">  	-<span class="number">2.1</span> 第三方平台解析可能会涉及到一个appid和appkey</span><br><span class="line">    -<span class="number">2.2</span> 根据封装好类改相应的参数拿到需要解析的验证码类型</span><br><span class="line">- <span class="number">3</span>登录请求携带的参数中把验证码对应的值改为第三方平台解析出来的结果</span><br><span class="line">- <span class="number">4</span>验证登录成功，响应的界面数据，可以用响应对象response.status_code做判断，如果状态码为<span class="number">200</span>，则表示成功</span><br><span class="line">- <span class="number">5</span>对登录成功后的页面再做解析处理的时候，需要携带cookie</span><br><span class="line">   -手动处理cookie（使用抓包工具定制cookie放在请求头中，不建议使用）</span><br><span class="line">   -自动处理cookie</span><br><span class="line">		cookie：存在客户端的键值对，携带cookie会让服务端知道所创建的cookie信息</span><br><span class="line">    session会话对象：</span><br><span class="line">    	-作用：</span><br><span class="line">        	<span class="number">1.</span>可以进行请求的发送</span><br><span class="line">            <span class="number">2.</span>如果请求过程中产生了cookie，则该cookie会被自动存储。携带在该session中 </span><br><span class="line">      - <span class="number">5.1</span>创建一个session对象：session = request.Session()</span><br><span class="line">      - <span class="number">5.2</span>使用session对象进行模拟登录post请求的发送（cookie就会存储在session中） </span><br><span class="line">          session = requests.Session()</span><br><span class="line">    response = session.post(url=img_url, headers=headers,data=img_data)</span><br></pre></td></tr></table></figure>

<h2 id="5-http与https协议"><a href="#5-http与https协议" class="headerlink" title="5 http与https协议"></a>5 http与https协议</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http: 无状态连接</span><br><span class="line">https: http+ssl()</span><br></pre></td></tr></table></figure>

<h2 id="6-代理操作"><a href="#6-代理操作" class="headerlink" title="6 代理操作"></a>6 代理操作</h2><p>代理：破解封IP这种反爬机制</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 代理：破解封IP这种反爬机制</span></span><br><span class="line"><span class="comment"># 什么是代理：代理服务器</span></span><br><span class="line"><span class="comment"># 代理的作用：</span></span><br><span class="line">	-<span class="number">1</span>突破自身IP访问的限制</span><br><span class="line">    -<span class="number">2</span>可以隐藏自身真实IP</span><br><span class="line"><span class="comment"># 代理相关的网站</span></span><br><span class="line"> - 快代理</span><br><span class="line"> - 西祠代理</span><br><span class="line"> - www.goubanjia.com</span><br><span class="line"> - 蜻蜓代理</span><br><span class="line">代理Ip的类型</span><br><span class="line">-http：应用到http协议对应的请求URL</span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/s?i&amp;wd=ip&#x27;</span></span><br><span class="line">page_text = requests.get(url=url, headers=headers, proxies=&#123;<span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;120.52.73.1:8095&#x27;</span>&#125;).text</span><br><span class="line"></span><br><span class="line">-https：应用到https协议对应的请求URL</span><br><span class="line">url = <span class="string">&#x27;https://www.baidu.com/s?i&amp;wd=ip&#x27;</span></span><br><span class="line">page_text = requests.get(url=url, headers=headers, proxies=&#123;<span class="string">&#x27;https&#x27;</span>:<span class="string">&#x27;120.52.73.1:8095&#x27;</span>&#125;).text</span><br><span class="line"></span><br><span class="line"><span class="comment"># 代理ip的匿名度</span></span><br><span class="line">	- 透明：服务器知道该次请求使用了代理，也知道请求对应的真实ip</span><br><span class="line">    - 匿名：知道使用了代理，但是不知道真实的ip（不知道本机的ip）</span><br><span class="line">    - 高匿：不知道使用了代理，更不知道本机的ip地址</span><br><span class="line"><span class="comment"># 反反爬机制：</span></span><br><span class="line">	使用代理进行发送请求</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="7-re模块对js代码指定过滤"><a href="#7-re模块对js代码指定过滤" class="headerlink" title="7 re模块对js代码指定过滤"></a>7 re模块对js代码指定过滤</h2><p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805013247183.png" alt="爬虫"></p>
<p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805013647300.png" alt="爬虫"></p>
<p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805013936878.png" alt="爬虫"></p>
<h2 id="8-单线程-异步协程"><a href="#8-单线程-异步协程" class="headerlink" title="8 单线程+异步协程"></a>8 单线程+异步协程</h2><p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805014139441.png" alt="爬虫"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span>(<span class="params">task</span>):</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;i am callback&#x27;</span>, task.result())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特殊函数</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_request</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="keyword">await</span> asyncio.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;下载成功&#x27;</span>, url)</span><br><span class="line">    <span class="keyword">return</span> url</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    <span class="string">&#x27;www.baidu.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;www.jd.com&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tasks = []</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    url = get_request(url)</span><br><span class="line">    task = asyncio.ensure_future(url)  <span class="comment"># 封装一个任务对象</span></span><br><span class="line">    task.add_done_callback(callback)  <span class="comment"># 绑定回调函数</span></span><br><span class="line">    tasks.append(task)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()  <span class="comment"># 创建一个事件循环对象</span></span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks)) <span class="comment"># 将协程对象注册到loop中，然后启动loop</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;耗时&#x27;</span>, time.time() - start)</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    task.result()</span></span><br><span class="line"><span class="string">        接收特殊函数的返回值</span></span><br><span class="line"><span class="string">        下载成功 www.baidu.com</span></span><br><span class="line"><span class="string">        下载成功 www.jd.com</span></span><br><span class="line"><span class="string">        i am callback www.baidu.com</span></span><br><span class="line"><span class="string">        i am callback www.jd.com</span></span><br><span class="line"><span class="string">        耗时 2.001952648162842</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="9-超级鹰平台"><a href="#9-超级鹰平台" class="headerlink" title="9 超级鹰平台"></a>9 超级鹰平台</h2><p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20210805021522176.png" alt="爬虫"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-<span class="number">1</span> 注册普通用户</span><br><span class="line">-<span class="number">2</span> 登录普通用户</span><br><span class="line">-<span class="number">3</span>  题分查询</span><br><span class="line">-<span class="number">4</span>  创建一个软件（<span class="built_in">id</span>）(进入用户中心-软件ID)</span><br><span class="line">-<span class="number">5</span>  下载示例代码 （点击开发文档-python）</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="xpath表达式提取"><a href="#xpath表达式提取" class="headerlink" title="xpath表达式提取"></a>xpath表达式提取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">/:表示的是从根节点开始定位，表示的是一个层级</span></span><br><span class="line"><span class="string">//:表示的是多个层级，可以表示从任意位置开始定位</span></span><br><span class="line"><span class="string">属性定位 </span></span><br><span class="line"><span class="string">        //div[@class=&quot;blog-link&quot;]</span></span><br><span class="line"><span class="string">索引定位 （索引是从1开始的）</span></span><br><span class="line"><span class="string">        //div[@class=&quot;blog-link&quot;]//li[2]</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">取文本</span></span><br><span class="line"><span class="string">    - /text() 获取的是标签中直系的文本内容</span></span><br><span class="line"><span class="string">    - //text() 获取的是标签中非直系的文本内容（所有的文本内容）</span></span><br><span class="line"><span class="string">取属性</span></span><br><span class="line"><span class="string">    //标签名 /ningmeng/@src</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>

<h1 id="aiohttp模块"><a href="#aiohttp模块" class="headerlink" title="aiohttp模块"></a>aiohttp模块</h1><ul>
<li>基于异步网络请求的模块</li>
</ul>
<p> flask启动一个应用服务器测试</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">from flask import Flask, render_template</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/lhj&#x27;)</span><br><span class="line">def index_lhj():</span><br><span class="line">    time.sleep(2)</span><br><span class="line">    return render_template(&#x27;test.html&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/lyh&#x27;)</span><br><span class="line">def index_lyh():</span><br><span class="line">    time.sleep(2)</span><br><span class="line">    return render_template(&#x27;test.html&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">@app.route(&#x27;/lxx&#x27;)</span><br><span class="line">def index_lxx():</span><br><span class="line">    time.sleep(2)</span><br><span class="line">    return render_template(&#x27;test.html&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure>

<p>测试aiohttp异步请求</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line">start = time.time()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">callback</span>(<span class="params">task</span>):</span></span><br><span class="line">    page_text = task.result()</span><br><span class="line">    tree = etree.HTML(page_text)</span><br><span class="line">    parse_data = tree.xpath(<span class="string">&#x27;//li/text()&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(parse_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 特殊函数</span></span><br><span class="line"><span class="comment"># 注意：</span></span><br><span class="line"><span class="comment"># 每一个with要加上async（表示异步操作）在每一个阻塞的前面加上await</span></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">get_request</span>(<span class="params">url</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;基于aiohttp发送的异步请求模块&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession() <span class="keyword">as</span> session:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;基于请求发送有延时操作的用await关键字&quot;&quot;&quot;</span></span><br><span class="line">                <span class="string">&quot;&quot;&quot;get(url,headers,param,proxy=&#x27;&#x27;,)代理不再是字典而是字符串&quot;&quot;&quot;</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;get(url,headers,data,proxy=&#x27;&#x27;,)代理不再是字典而是字符串&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">async</span> <span class="keyword">with</span> <span class="keyword">await</span> session.get(url) <span class="keyword">as</span> response:</span><br><span class="line">            <span class="string">&quot;&quot;&quot;text()返回字符串形式的响应数据&quot;&quot;&quot;</span></span><br><span class="line">            <span class="string">&quot;&quot;&quot;read()返回二进制形式的响应数据&quot;&quot;&quot;</span></span><br><span class="line">            <span class="string">&quot;&quot;&quot;json()返回的就是json数据&quot;&quot;&quot;</span></span><br><span class="line">            page_text = <span class="keyword">await</span> response.text()</span><br><span class="line">            <span class="keyword">return</span> page_text</span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lhj&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lyh&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;http://127.0.0.1:5000/lxx&#x27;</span>,</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tasks = []</span><br><span class="line"><span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">    res = get_request(url)</span><br><span class="line">    task = asyncio.ensure_future(res)  <span class="comment"># 封装一个任务对象</span></span><br><span class="line">    task.add_done_callback(callback)  <span class="comment"># 绑定回调函数</span></span><br><span class="line">    tasks.append(task)</span><br><span class="line"></span><br><span class="line">loop = asyncio.get_event_loop()  <span class="comment"># 创建一个事件循环对象</span></span><br><span class="line">loop.run_until_complete(asyncio.wait(tasks))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;耗时&#x27;</span>, time.time() - start)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">输出结果</span></span><br><span class="line"><span class="string">[&#x27;i am superman &#x27;, &#x27;i am hero &#x27;, &#x27;i am super &#x27;]</span></span><br><span class="line"><span class="string">[&#x27;i am superman &#x27;, &#x27;i am hero &#x27;, &#x27;i am super &#x27;]</span></span><br><span class="line"><span class="string">[&#x27;i am superman &#x27;, &#x27;i am hero &#x27;, &#x27;i am super &#x27;]</span></span><br><span class="line"><span class="string">耗时 2.0634195804595947</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<h1 id="requests模块"><a href="#requests模块" class="headerlink" title="requests模块"></a>requests模块</h1><ul>
<li>request.get是基于同步发起的请求</li>
</ul>
<h2 id="1-get请求"><a href="#1-get请求" class="headerlink" title="1 get请求"></a>1 get请求</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>、基本请求</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">&#x27;http://dig.chouti.com/&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line"><span class="number">2</span>、带参数的GET请求-&gt;params</span><br><span class="line"></span><br><span class="line">复制代码</span><br><span class="line"><span class="comment">#在请求头内将自己伪装成浏览器，否则百度不会正常返回页面内容</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">&#x27;https://www.baidu.com/s?wd=python&amp;pn=1&#x27;</span>,</span><br><span class="line">                      headers=&#123;</span><br><span class="line">                        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.75 Safari/537.36&#x27;</span>,</span><br><span class="line">                      &#125;)</span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#如果查询关键词是中文或者有其他特殊符号，则不得不进行url编码</span></span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line">wd=<span class="string">&#x27;egon老师&#x27;</span></span><br><span class="line">encode_res=urlencode(&#123;<span class="string">&#x27;k&#x27;</span>:wd&#125;,encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">keyword=encode_res.split(<span class="string">&#x27;=&#x27;</span>)[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(keyword)</span><br><span class="line"><span class="comment"># 然后拼接成url</span></span><br><span class="line">url=<span class="string">&#x27;https://www.baidu.com/s?wd=%s&amp;pn=1&#x27;</span> %keyword</span><br><span class="line"></span><br><span class="line">response=requests.get(url,</span><br><span class="line">                      headers=&#123;</span><br><span class="line">                        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.75 Safari/537.36&#x27;</span>,</span><br><span class="line">                      &#125;)</span><br><span class="line">res1=response.text</span><br><span class="line">复制代码</span><br><span class="line">复制代码</span><br><span class="line"><span class="comment">#上述操作可以用requests模块的一个params参数搞定，本质还是调用urlencode</span></span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line">wd=<span class="string">&#x27;egon老师&#x27;</span></span><br><span class="line">pn=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">response=requests.get(<span class="string">&#x27;https://www.baidu.com/s&#x27;</span>,</span><br><span class="line">                      params=&#123;</span><br><span class="line">                          <span class="string">&#x27;wd&#x27;</span>:wd,</span><br><span class="line">                          <span class="string">&#x27;pn&#x27;</span>:pn</span><br><span class="line">                      &#125;,</span><br><span class="line">                      headers=&#123;</span><br><span class="line">                        <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.75 Safari/537.36&#x27;</span>,</span><br><span class="line">                      &#125;)</span><br><span class="line">res2=response.text</span><br><span class="line"></span><br><span class="line"><span class="comment">#验证结果，打开a.html与b.html页面内容一样</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;a.html&#x27;</span>,<span class="string">&#x27;w&#x27;</span>,encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(res1) </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;b.html&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(res2)</span><br><span class="line">复制代码</span><br><span class="line"><span class="number">3</span>、带参数的GET请求-&gt;headers</span><br><span class="line"></span><br><span class="line"><span class="comment">#通常我们在发送请求时都需要带上请求头，请求头是将自身伪装成浏览器的关键，常见的有用的请求头如下</span></span><br><span class="line">Host</span><br><span class="line">Referer <span class="comment">#大型网站通常都会根据该参数判断请求的来源</span></span><br><span class="line">User-Agent <span class="comment">#客户端</span></span><br><span class="line">Cookie <span class="comment">#Cookie信息虽然包含在请求头里，但requests模块有单独的参数来处理他，headers=&#123;&#125;内就不要放它了</span></span><br><span class="line">复制代码</span><br><span class="line"><span class="comment">#添加headers(浏览器会识别请求头,不加可能会被拒绝访问,比如访问https://www.zhihu.com/explore)</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>)</span><br><span class="line">response.status_code <span class="comment">#500</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#自己定制headers</span></span><br><span class="line">headers=&#123;</span><br><span class="line">    <span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.76 Mobile Safari/537.36&#x27;</span>,</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">respone=requests.get(<span class="string">&#x27;https://www.zhihu.com/explore&#x27;</span>,</span><br><span class="line">                     headers=headers)</span><br><span class="line"><span class="built_in">print</span>(respone.status_code) <span class="comment">#200</span></span><br><span class="line">复制代码</span><br><span class="line"><span class="number">4</span>、带参数的GET请求-&gt;cookies</span><br><span class="line"></span><br><span class="line">复制代码</span><br><span class="line"><span class="comment">#登录github，然后从浏览器中获取cookies，以后就可以直接拿着cookie登录了，无需输入用户名密码</span></span><br><span class="line"><span class="comment">#用户名:egonlin 邮箱378533872@qq.com 密码lhf@123</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">Cookies=&#123;   <span class="string">&#x27;user_session&#x27;</span>:<span class="string">&#x27;wGMHFJKgDcmRIVvcA14_Wrt_3xaUyJNsBnPbYzEL6L0bHcfc&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">response=requests.get(<span class="string">&#x27;https://github.com/settings/emails&#x27;</span>,</span><br><span class="line">             cookies=Cookies) <span class="comment">#github对请求头没有什么限制，我们无需定制user-agent，对于其他网站可能还需要定制</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;378533872@qq.com&#x27;</span> <span class="keyword">in</span> response.text) <span class="comment">#True</span></span><br></pre></td></tr></table></figure>

<h2 id="2-post请求"><a href="#2-post请求" class="headerlink" title="2 post请求"></a>2 post请求</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#GET请求</span></span><br><span class="line">HTTP默认的请求方法就是GET</span><br><span class="line">     * 没有请求体</span><br><span class="line">     * 数据必须在1K之内！</span><br><span class="line">     * GET请求数据会暴露在浏览器的地址栏中</span><br><span class="line"></span><br><span class="line">GET请求常用的操作：</span><br><span class="line">       <span class="number">1.</span> 在浏览器的地址栏中直接给出URL，那么就一定是GET请求</span><br><span class="line">       <span class="number">2.</span> 点击页面上的超链接也一定是GET请求</span><br><span class="line">       <span class="number">3.</span> 提交表单时，表单默认使用GET请求，但可以设置为POST</span><br><span class="line"></span><br><span class="line"><span class="comment">#POST请求</span></span><br><span class="line">(<span class="number">1</span>). 数据不会出现在地址栏中</span><br><span class="line">(<span class="number">2</span>). 数据的大小没有上限</span><br><span class="line">(<span class="number">3</span>). 有请求体</span><br><span class="line">(<span class="number">4</span>). 请求体中如果存在中文，会使用URL编码！</span><br><span class="line"></span><br><span class="line"><span class="comment">#！！！requests.post()用法与requests.get()完全一致，特殊的是requests.post()有一个data参数，用来存放请求体数据</span></span><br></pre></td></tr></table></figure>

<h2 id="2-1-发送post请求模拟登录"><a href="#2-1-发送post请求模拟登录" class="headerlink" title="2.1 发送post请求模拟登录"></a>2.1 发送post请求模拟登录</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">session = requests.session()</span><br><span class="line"><span class="comment"># 第一次请求</span></span><br><span class="line">r1 = session.get(<span class="string">&#x27;https://github.com/login&#x27;</span>)</span><br><span class="line">authenticity_token = re.findall(<span class="string">r&#x27;name=&quot;authenticity_token&quot;.*?value=&quot;(.*?)&quot;&#x27;</span>, r1.text)[<span class="number">0</span>]  <span class="comment"># 从页面中拿到CSRF TOKEN</span></span><br><span class="line"><span class="built_in">print</span>(authenticity_token)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二次请求</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;Form Data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">commit: Sign in</span></span><br><span class="line"><span class="string">authenticity_token: f68TeCuz360B5Ag/DFlRmGJwkvICneQH7E7EP8w7ZeZyg7rdvqeNXA1Vo3163Z+QS8aaF8s+06J6qgECBFr+qQ==</span></span><br><span class="line"><span class="string">login: liu199956</span></span><br><span class="line"><span class="string">password: 11</span></span><br><span class="line"><span class="string">trusted_device: </span></span><br><span class="line"><span class="string">webauthn-support: supported</span></span><br><span class="line"><span class="string">webauthn-iuvpaa-support: supported</span></span><br><span class="line"><span class="string">return_to: </span></span><br><span class="line"><span class="string">allow_signup: </span></span><br><span class="line"><span class="string">client_id: </span></span><br><span class="line"><span class="string">integration: </span></span><br><span class="line"><span class="string">required_field_d6e6: </span></span><br><span class="line"><span class="string">timestamp: 1611157305298</span></span><br><span class="line"><span class="string">timestamp_secret: cc5cbd21bb8363de56c9fbb9d2123c0574787020e7bdf329630b23c997c79c24</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">&#x27;commit&#x27;</span>: <span class="string">&#x27;Sign in&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;webauthn-support&#x27;</span>: <span class="string">&#x27;supported&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;authenticity_token&#x27;</span>: authenticity_token,</span><br><span class="line">    <span class="string">&#x27;login&#x27;</span>: <span class="string">&#x27;1026170773@qq.com&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;password&#x27;</span>: <span class="string">&#x27;liu199556&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;webauthn-iuvpaa-support&#x27;</span>: <span class="string">&#x27;supported&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;timestamp&#x27;</span>: <span class="number">1611157305298</span>,</span><br><span class="line">    <span class="string">&#x27;timestamp_secret&#x27;</span>: <span class="string">&#x27;cc5cbd21bb8363de56c9fbb9d2123c0574787020e7bdf329630b23c997c79c24&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">r2 = session.post(<span class="string">&#x27;https://github.com/session&#x27;</span>,</span><br><span class="line">                  data=data,</span><br><span class="line">                  )</span><br><span class="line"></span><br><span class="line"><span class="comment">#第三次请求</span></span><br><span class="line">r3=session.get(<span class="string">&#x27;https://github.com/settings/emails&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;1026170773@qq.com&#x27;</span> <span class="keyword">in</span> r3.text) <span class="comment">#True</span></span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">一 目标站点分析</span><br><span class="line">    浏览器输入https://gitee.com/login</span><br><span class="line">    然后输入错误的账号密码，抓包</span><br><span class="line">    发现登录行为是post提交到：https://gitee.com/login</span><br><span class="line">    而且请求头包含cookie</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">二 流程分析</span><br><span class="line">    先GET：https://github.com/login拿到初始cookie与</span><br><span class="line">    返回POST：https://gitee.com/check_user_captcha， 带上初始cookie，</span><br><span class="line">        token: 6d65abaf9a8647c289a0fc1abb61535a</span><br><span class="line">        authenticate: e25522a8498a4818b12b2ee11be32d59</span><br><span class="line">        <span class="built_in">type</span>: yunpian</span><br><span class="line">    最后拿到登录cookie</span><br><span class="line"></span><br><span class="line">​```</span><br><span class="line">ps：如果密码时密文形式，则可以先输错账号，输对密码，然后到浏览器中拿到加密后的密码，github的密码是明文</span><br><span class="line">​```</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">import requests</span></span><br><span class="line"><span class="string">import re</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#第一次请求</span></span><br><span class="line"><span class="string">r1=requests.get(&#x27;https://github.com/login&#x27;)</span></span><br><span class="line"><span class="string">r1_cookie=r1.cookies.get_dict() #拿到初始cookie(未被授权)</span></span><br><span class="line"><span class="string">authenticity_token=re.findall(r&#x27;name=&quot;authenticity_token&quot;.*?value=&quot;(.*?)&quot;&#x27;,r1.text)[0] #从页面中拿到CSRF TOKEN</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#第二次请求：带着初始cookie和TOKEN发送POST请求给登录页面，带上账号密码</span></span><br><span class="line"><span class="string">data=&#123;</span></span><br><span class="line"><span class="string">    &#x27;commit&#x27;:&#x27;Sign in&#x27;,</span></span><br><span class="line"><span class="string">    &#x27;utf8&#x27;:&#x27;✓&#x27;,</span></span><br><span class="line"><span class="string">    &#x27;authenticity_token&#x27;:authenticity_token,</span></span><br><span class="line"><span class="string">    &#x27;login&#x27;:&#x27;317828332@qq.com&#x27;,</span></span><br><span class="line"><span class="string">    &#x27;password&#x27;:&#x27;alex3714&#x27;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">r2=requests.post(&#x27;https://github.com/session&#x27;,</span></span><br><span class="line"><span class="string">             data=data,</span></span><br><span class="line"><span class="string">             cookies=r1_cookie</span></span><br><span class="line"><span class="string">             )</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">login_cookie=r2.cookies.get_dict()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">#第三次请求：以后的登录，拿着login_cookie就可以,比如访问一些个人配置</span></span><br><span class="line"><span class="string">r3=requests.get(&#x27;https://github.com/settings/emails&#x27;,</span></span><br><span class="line"><span class="string">                cookies=login_cookie)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">print(&#x27;317828332@qq.com&#x27; in r3.text) #True</span></span><br></pre></td></tr></table></figure>



<h2 id="3-响应Response"><a href="#3-响应Response" class="headerlink" title="3 响应Response"></a>3 响应Response</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">respone=requests.get(<span class="string">&#x27;http://www.jianshu.com&#x27;</span>)</span><br><span class="line"><span class="comment"># respone属性</span></span><br><span class="line"><span class="built_in">print</span>(respone.text)</span><br><span class="line"><span class="built_in">print</span>(respone.content)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(respone.status_code)</span><br><span class="line"><span class="built_in">print</span>(respone.headers)</span><br><span class="line"><span class="built_in">print</span>(respone.cookies)</span><br><span class="line"><span class="built_in">print</span>(respone.cookies.get_dict())</span><br><span class="line"><span class="built_in">print</span>(respone.cookies.items())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(respone.url)</span><br><span class="line"><span class="built_in">print</span>(respone.history)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(respone.encoding)</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭：response.close()</span></span><br><span class="line"><span class="keyword">from</span> contextlib <span class="keyword">import</span> closing</span><br><span class="line"><span class="keyword">with</span> closing(requests.get(<span class="string">&#x27;xxx&#x27;</span>,stream=<span class="literal">True</span>)) <span class="keyword">as</span> response:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> response.iter_content():</span><br><span class="line">    <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2</span>、编码问题</span><br><span class="line"><span class="comment">#编码问题</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">response=requests.get(<span class="string">&#x27;http://www.autohome.com/news&#x27;</span>)</span><br><span class="line"><span class="comment"># response.encoding=&#x27;gbk&#x27; #汽车之家网站返回的页面内容为gb2312编码的，而requests的默认编码为ISO-8859-1，如果不设置成gbk则中文乱码</span></span><br><span class="line"><span class="built_in">print</span>(response.text)</span><br><span class="line"></span><br><span class="line"><span class="number">4</span>、 使用代理</span><br><span class="line"><span class="comment">#官网链接: http://docs.python-requests.org/en/master/user/advanced/#proxies</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#代理设置:先发送请求给代理,然后由代理帮忙发送(封ip是常见的事情)</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxies=&#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;http://egon:123@localhost:9743&#x27;</span>,<span class="comment">#带用户名密码的代理,@符号前是用户名与密码</span></span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>:<span class="string">&#x27;http://localhost:9743&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>:<span class="string">&#x27;https://localhost:9743&#x27;</span>,</span><br><span class="line">&#125;</span><br><span class="line">respone=requests.get(<span class="string">&#x27;https://www.12306.cn&#x27;</span>,</span><br><span class="line">                     proxies=proxies)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(respone.status_code)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#支持socks代理,安装:pip install requests[socks]</span></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">proxies = &#123;</span><br><span class="line">    <span class="string">&#x27;http&#x27;</span>: <span class="string">&#x27;socks5://user:pass@host:port&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https&#x27;</span>: <span class="string">&#x27;socks5://user:pass@host:port&#x27;</span></span><br><span class="line">&#125;</span><br><span class="line">respone=requests.get(<span class="string">&#x27;https://www.12306.cn&#x27;</span>,</span><br><span class="line">                     proxies=proxies)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(respone.status_code)</span><br><span class="line"></span><br><span class="line"><span class="number">6</span>、上传文件</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">files=&#123;<span class="string">&#x27;file&#x27;</span>:<span class="built_in">open</span>(<span class="string">&#x27;a.jpg&#x27;</span>,<span class="string">&#x27;rb&#x27;</span>)&#125;</span><br><span class="line">respone=requests.post(<span class="string">&#x27;http://httpbin.org/post&#x27;</span>,files=files)</span><br><span class="line"><span class="built_in">print</span>(respone.status_code)</span><br></pre></td></tr></table></figure>

<h1 id="selenium模块"><a href="#selenium模块" class="headerlink" title="selenium模块"></a>selenium模块</h1><h2 id="1-selenium介绍"><a href="#1-selenium介绍" class="headerlink" title="1 selenium介绍"></a>1 selenium介绍</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 自动化测试工具，控制浏览器，模拟人的行为，做爬虫为了解决使用requests模块无法执行ajax获取数据</span><br><span class="line"><span class="number">2</span> 使用selenium+半人工登录，获取cookie-----》给requests模块使用</span><br></pre></td></tr></table></figure>

<h2 id="2-selenium基本使用"><a href="#2-selenium基本使用" class="headerlink" title="2 selenium基本使用"></a>2 selenium基本使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拿到一个微软浏览器</span></span><br><span class="line"><span class="comment"># 打开浏览器指定驱动在哪</span></span><br><span class="line">bro = webdriver.Edge(executable_path=<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line"></span><br><span class="line">bro.get(<span class="string">&#x27;http://www.baidu.com&#x27;</span>)</span><br><span class="line">time.sleep(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 关闭浏览器</span></span><br><span class="line">bro.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 无界面浏览器</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="3-selenium的其它使用"><a href="#3-selenium的其它使用" class="headerlink" title="3 selenium的其它使用"></a>3 selenium的其它使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"></span><br><span class="line">bro=webdriver.Chrome(executable_path=<span class="string">&#x27;chromedriver.exe&#x27;</span>)</span><br><span class="line"><span class="comment"># bro.get(&#x27;http://www.baidu.com&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># print(bro.page_source)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择器</span></span><br><span class="line"><span class="comment"># 1、find_element_by_id                通过id获取控件</span></span><br><span class="line"><span class="comment"># 2、find_element_by_link_text         通过a标签的文本获取标签</span></span><br><span class="line"><span class="comment"># 3、find_element_by_partial_link_text 通过a标签的文本模糊匹配获取标签</span></span><br><span class="line"><span class="comment"># 4、find_element_by_tag_name          通过标签名找</span></span><br><span class="line"><span class="comment"># 5、find_element_by_class_name        通过类名找</span></span><br><span class="line"><span class="comment"># 6、find_element_by_name              通过name属性找</span></span><br><span class="line"><span class="comment"># 7、find_element_by_css_selector      css选择器</span></span><br><span class="line"><span class="comment"># 8、find_element_by_xpath             xpath选择器</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># input_1=bro.find_element_by_css_selector(&#x27;#kw&#x27;)</span></span><br><span class="line"><span class="comment"># # 往输入框中写文字</span></span><br><span class="line"><span class="comment"># input_1.send_keys(&#x27;美女&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># search_btn=bro.find_element_by_css_selector(&#x27;#su&#x27;)</span></span><br><span class="line"><span class="comment"># search_btn.click()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取某个标签的属性,位置,id,名字..</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># input_1=bro.find_element_by_css_selector(&#x27;#kw&#x27;)</span></span><br><span class="line"><span class="comment"># print(input_1.id)</span></span><br><span class="line"><span class="comment"># print(input_1.tag_name)</span></span><br><span class="line"><span class="comment"># print(input_1.get_attribute(&#x27;maxlength&#x27;))</span></span><br><span class="line"><span class="comment"># print(input_1.location)</span></span><br><span class="line"><span class="comment"># print(input_1.size)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 等待元素被加载(显示等待,隐士等待)</span></span><br><span class="line"><span class="comment"># bro.implicitly_wait(10)  # 隐士等待,等待所有,再下方再去找一个控件,如果控件没有加载出来,最多等待10s</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示等待(基本不用),指定等待某个控件几秒</span></span><br><span class="line"><span class="comment"># from selenium.webdriver.support.wait import WebDriverWait</span></span><br><span class="line"><span class="comment"># from selenium.webdriver.support import expected_conditions as EC</span></span><br><span class="line"><span class="comment"># from selenium.webdriver.common.by import By #按照什么方式查找，By.ID,By.CSS_SELECTOR</span></span><br><span class="line"><span class="comment"># wait=WebDriverWait(bro,10)</span></span><br><span class="line"><span class="comment"># wait.until(EC.presence_of_element_located((By.ID,&#x27;kw&#x27;)))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 控件其它操作</span></span><br><span class="line"><span class="comment"># 点击操作</span></span><br><span class="line"><span class="comment"># search_btn=bro.find_element_by_css_selector(&#x27;#su&#x27;)</span></span><br><span class="line"><span class="comment"># search_btn.click()  # 点击操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># input_1=bro.find_element_by_css_selector(&#x27;#kw&#x27;)</span></span><br><span class="line"><span class="comment"># # 往输入框中写文字</span></span><br><span class="line"><span class="comment"># # 清空操作</span></span><br><span class="line"><span class="comment"># input_1.send_keys(&#x27;美女&#x27;)</span></span><br><span class="line"><span class="comment"># time.sleep(1)</span></span><br><span class="line"><span class="comment"># input_1.clear()</span></span><br><span class="line"><span class="comment"># input_1.send_keys(&#x27;帅哥&#x27;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 执行js</span></span><br><span class="line"><span class="comment"># bro.get(&#x27;https://www.pearvideo.com/video_1715923&#x27;)</span></span><br><span class="line"><span class="comment"># bro.execute_script(&#x27;alert(urlMap.registerUrl)&#x27;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># bro.execute_script(&#x27;scroll(0,30000)&#x27;)  # 滑倒屏幕底部，有的页面滑倒底部自动加载数据</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟浏览器前进后退</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># bro.get(&#x27;http://www.baidu.com&#x27;)</span></span><br><span class="line"><span class="comment"># bro.get(&#x27;http://www.taobao.com&#x27;)</span></span><br><span class="line"><span class="comment"># bro.get(&#x27;http://www.cnblogs.com&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># bro.back()</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># time.sleep(1)</span></span><br><span class="line"><span class="comment"># bro.forward()</span></span><br><span class="line"><span class="comment"># time.sleep(1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># bro.get(&#x27;http://www.cnblogs.com&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># time.sleep(30)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### cookie的处理</span></span><br><span class="line"><span class="comment"># print(type(bro.get_cookies())) # 把所有cookie取出来</span></span><br><span class="line"><span class="comment"># cookies=bro.get_cookies()</span></span><br><span class="line"><span class="comment"># import json</span></span><br><span class="line"><span class="comment"># with open(&#x27;cookie.json&#x27;,&#x27;w&#x27;) as f:</span></span><br><span class="line"><span class="comment">#     json.dump(cookies,f)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># # 取到cookie之后，存到文件中</span></span><br><span class="line"><span class="comment"># # 再打开一个页面，还是这个网站，把cookie之间写入</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># time.sleep(1)</span></span><br><span class="line"><span class="comment"># # 关闭浏览器</span></span><br><span class="line"><span class="comment"># bro.close()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">### 选项卡管理</span></span><br><span class="line"><span class="comment"># browser=webdriver.Chrome()</span></span><br><span class="line"><span class="comment"># browser.get(&#x27;https://www.baidu.com&#x27;)</span></span><br><span class="line"><span class="comment"># browser.execute_script(&#x27;window.open()&#x27;)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># print(browser.window_handles) #获取所有的选项卡</span></span><br><span class="line"><span class="comment"># browser.switch_to_window(browser.window_handles[1])</span></span><br><span class="line"><span class="comment"># browser.get(&#x27;https://www.taobao.com&#x27;)</span></span><br><span class="line"><span class="comment"># time.sleep(2)</span></span><br><span class="line"><span class="comment"># browser.switch_to_window(browser.window_handles[0])</span></span><br><span class="line"><span class="comment"># browser.get(&#x27;https://www.sina.com.cn&#x27;)</span></span><br><span class="line"><span class="comment"># browser.close()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 异常捕获</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    browser=webdriver.Chrome()</span><br><span class="line">    browser.get(<span class="string">&#x27;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#x27;</span>)</span><br><span class="line">    browser.switch_to.frame(<span class="string">&#x27;iframssseResult&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    browser.close()  <span class="comment"># 关闭浏览器</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="4-selenium-爬取京东商品信息"><a href="#4-selenium-爬取京东商品信息" class="headerlink" title="4 selenium 爬取京东商品信息"></a>4 selenium 爬取京东商品信息</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> selenium.webdriver.common.keys <span class="keyword">import</span> Keys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义爬取函数</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_goods</span>(<span class="params">bro</span>):</span></span><br><span class="line">    <span class="comment"># 滑倒屏幕底部</span></span><br><span class="line">    bro.execute_script(<span class="string">&#x27;scroll(0,document.body.scrollHeight)&#x27;</span>)</span><br><span class="line">    li_list = bro.find_elements_by_class_name(<span class="string">&#x27;gl-item&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            img_url = li.find_element_by_css_selector(<span class="string">&#x27;.p-img&gt;a&gt;img&#x27;</span>).get_attribute(<span class="string">&#x27;src&#x27;</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> img_url:</span><br><span class="line">                img_url = li.find_element_by_css_selector(<span class="string">&#x27;.p-img&gt;a&gt;img&#x27;</span>).get_attribute(<span class="string">&#x27;data-lazy-img&#x27;</span>)</span><br><span class="line">            <span class="comment"># img_url = &#x27;https:&#x27; + img_url</span></span><br><span class="line"></span><br><span class="line">            name = li.find_element_by_css_selector(<span class="string">&#x27;.p-name em&#x27;</span>).text</span><br><span class="line">            url = li.find_element_by_css_selector(<span class="string">&#x27;.p-img&gt;a&#x27;</span>).get_attribute(<span class="string">&#x27;href&#x27;</span>)</span><br><span class="line">            price = li.find_element_by_css_selector(<span class="string">&#x27;.p-price i&#x27;</span>).text</span><br><span class="line">            commit = li.find_element_by_css_selector(<span class="string">&#x27;.p-commit a&#x27;</span>).text</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">            商品名称：%s</span></span><br><span class="line"><span class="string">            商品价格：%s</span></span><br><span class="line"><span class="string">            商品链接：%s</span></span><br><span class="line"><span class="string">            图片链接：%s</span></span><br><span class="line"><span class="string">            商品评论数：%s</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            &#x27;&#x27;&#x27;</span> % (name, price, url, img_url, commit))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 点击下一页</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">next</span> = bro.find_element_by_partial_link_text(<span class="string">&#x27;下一页&#x27;</span>)</span><br><span class="line">    <span class="built_in">next</span>.click()</span><br><span class="line">    <span class="comment"># 再解析下一页的内容</span></span><br><span class="line">    get_goods(bro)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bro = webdriver.Edge(executable_path=<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    bro.get(<span class="string">&#x27;https://www.jd.com/&#x27;</span>)</span><br><span class="line">    <span class="comment"># 隐士等待</span></span><br><span class="line"></span><br><span class="line">    bro.implicitly_wait(<span class="number">10</span>)</span><br><span class="line">    search_in = bro.find_element_by_id(<span class="string">&#x27;key&#x27;</span>)</span><br><span class="line">    search_in.send_keys(<span class="string">&#x27;男士内衣&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    search_in.send_keys(Keys.ENTER)  <span class="comment"># 敲击回车</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># bro.page_source---&gt;bs4--lxml</span></span><br><span class="line">    get_goods(bro)</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="built_in">print</span>(e)</span><br><span class="line"></span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    bro.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h1 id="scrapy模块"><a href="#scrapy模块" class="headerlink" title="scrapy模块"></a>scrapy模块</h1><h2 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span> 框架---》别人帮我们写了好多代码，我们只需要再固定的位置写固定的代码</span><br><span class="line"><span class="number">1</span> 爬虫界的django---》好多东西用起来跟django很像</span><br><span class="line"><span class="number">2</span> pip3 install scrapy  （依赖）</span><br><span class="line">	-win平台：</span><br><span class="line">        <span class="number">1</span>、pip3 install wheel </span><br><span class="line">        <span class="number">3</span>、pip3 install lxml</span><br><span class="line">        <span class="number">4</span>、pip3 install pyopenssl（装这个装不上：更新pip,搜方案）</span><br><span class="line">        <span class="number">5</span>、下载并安装pywin32：https://github.com/mhammond/pywin32/releases</span><br><span class="line">        <span class="number">6</span>、下载twisted的wheel文件：http://www.lfd.uci.edu/~gohlke/pythonlibs/<span class="comment">#twisted</span></span><br><span class="line">        <span class="number">7</span>、执行pip3 install 下载目录\Twisted-<span class="number">17.9</span><span class="number">.0</span>-cp36-cp36m-win_amd64.whl</span><br><span class="line">        <span class="number">8</span>、pip3 install scrapy</span><br><span class="line"></span><br><span class="line"><span class="number">3</span> win平台有些模块不好装</span><br><span class="line">	-pip3 install wheel </span><br><span class="line">    -http://www.lfd.uci.edu/~gohlke/pythonlibs 下载相应的wheel文件</span><br><span class="line">    -pip3 install 把下载后的whl拖入即可（注意python，win版本）</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="number">4</span> 只要装完：scrapy 命令</span><br><span class="line">	-django创建项目：djangoadmin startproject 项目名（pycharm也可以直接创建）</span><br><span class="line">    -scrapy创建项目：scrapy startproject 项目名</span><br><span class="line">    -使用pycharm打开</span><br><span class="line">    -django中创建app ：python manage.py startapp app名字</span><br><span class="line">    -scrapy创建爬虫： scrapy genspider 爬虫名 爬虫的地址</span><br><span class="line">    			   - scrapy genspider cnblogs www.cnblogs.com</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="number">5</span> scrapy总结</span><br><span class="line">	-pip3 install scrapy</span><br><span class="line">    -scrapy startproject 项目名</span><br><span class="line">    -scrapy genspider 爬虫名 爬虫的地址</span><br><span class="line">    -scrapy crawl spiderName 执行工程（开始爬虫）</span><br></pre></td></tr></table></figure>

<p><strong>spiders</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FirstcrawlSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;爬虫文件的名称：就是爬虫源文件的唯一标识&quot;&quot;&quot;</span></span><br><span class="line">    name = <span class="string">&#x27;firstCrawl&#x27;</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;允许的域名：用来限定start_urls列表中哪些url可以进行请求发送&quot;&quot;&quot;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.baidu.com&#x27;</span>]</span><br><span class="line">    <span class="string">&quot;&quot;&quot;爬虫起始的url，可以写多个，该列表中的url会被scrapy自动进行请求的发送&quot;&quot;&quot;</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.baidu.com/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;用作数据解析，response参数表示的是请求成功后对应的响应参数&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py"></a><strong>settings.py</strong></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span>  <span class="comment"># 爬虫协议，不遵循</span></span><br><span class="line"></span><br><span class="line">LOG_LEVEL = <span class="string">&#x27;ERROR&#x27;</span>  <span class="comment"># 显示指定类型的日志信息</span></span><br><span class="line"></span><br><span class="line">USER_AGENT = <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36 Edg/85.0.564.51&#x27;</span> <span class="comment"># 浏览器标识</span></span><br><span class="line"></span><br><span class="line">- 管道配置</span><br><span class="line">ITEM_PIPELINES = &#123; </span><br><span class="line">    <span class="string">&#x27;scrapy_redis.pipelines.RedisPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">    <span class="comment"># &#x27;Scrapy.pipelines.CnblogsSpiderFilePipeline&#x27;: 300,  # 数字表示优先级，数字越小，优先级越大</span></span><br><span class="line">    <span class="string">&#x27;Scrapy.pipelines.CnblogsSpiderMysqlPipeline&#x27;</span>: <span class="number">400</span>,  <span class="comment"># 数字表示优先级，数字越小，优先级越大</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">IMAGES_STORE = <span class="string">&#x27;./imgs&#x27;</span>  <span class="comment"># 图片存储路径</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2-架构"><a href="#2-架构" class="headerlink" title="2 架构"></a>2 架构</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5大组件：</span></span><br><span class="line"><span class="number">1</span> 爬虫：SPIDERS</span><br><span class="line">	-刚刚创建的一个个爬虫（py文件，以后主要再这写）</span><br><span class="line"><span class="number">2</span> 引擎EGINE</span><br><span class="line">	-大总管，负责各个组件的沟通（写代码不涉及到），</span><br><span class="line">    -引擎负责控制系统所有组件之间的数据流，并在某些动作发生时触发事件</span><br><span class="line"><span class="number">3</span> pipline持久化</span><br><span class="line">	-爬完数据解析完，入库（py文件，存数据库，存文件，存redis，在这写）</span><br><span class="line">    -在items被提取后负责处理它们，主要包括清理、验证、持久化（比如存到数据库）等操作</span><br><span class="line"><span class="number">4</span> 调度器</span><br><span class="line">	-调度谁先被爬取，谁后爬取（通过配置来操作）</span><br><span class="line">    -用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL的优先级队列, 由它来决定下一个要抓取的网址是什么, 同时去除重复的网址</span><br><span class="line"><span class="number">5</span> 下载器</span><br><span class="line">	-真正取爬取数据的（写代码也不涉及）</span><br><span class="line"></span><br><span class="line"><span class="comment"># 两大中间件</span></span><br><span class="line"><span class="number">1</span> 爬虫中间件，介于爬虫和引擎之间，可以写多个（一般不写）</span><br><span class="line"><span class="number">2</span> 下载中间件，介于下载器和引擎之间，可以写多个（写的多）</span><br></pre></td></tr></table></figure>

<h2 id="3-目录介绍"><a href="#3-目录介绍" class="headerlink" title="3 目录介绍"></a>3 目录介绍</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Scrapy <span class="comment"># 项目名字</span></span><br><span class="line">    Scrapy <span class="comment"># 文件夹</span></span><br><span class="line">        spiders   <span class="comment"># 所有的爬虫文件都放在这个下面</span></span><br><span class="line">            __init__.py</span><br><span class="line">            chouti.py  <span class="comment"># 爬虫1  （写代码）</span></span><br><span class="line">            baidu.py   <span class="comment"># 爬虫2</span></span><br><span class="line">            cnblogs.py <span class="comment"># 爬虫3</span></span><br><span class="line">        settings.py <span class="comment"># 整个项目的配置文件</span></span><br><span class="line">        items.py    <span class="comment"># 写一些类，对比django的models    （写一些类）</span></span><br><span class="line">        middlewares.py <span class="comment"># 爬虫中间件和下载中间件都写在这  （写中间件）</span></span><br><span class="line">        pipelines.py  <span class="comment"># 持久化，存数据，文件，都在这写（数据清洗入库）  （写代码）</span></span><br><span class="line">    scrapy.cfg        <span class="comment"># 上线的配置文件 </span></span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h2 id="4-scrapy的简单使用"><a href="#4-scrapy的简单使用" class="headerlink" title="4 scrapy的简单使用"></a>4 scrapy的简单使用</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 运行爬虫</span><br><span class="line">	scrapy scrawl 爬虫名           打印运行日志</span><br><span class="line">    scrapy crawl cnblogs --nolog   不打印日志</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="number">2</span> 记住的</span><br><span class="line">	-解析（<span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>)）</span></span><br><span class="line"><span class="function">    	-<span class="title">css</span></span></span><br><span class="line"><span class="function">        -<span class="title">xpath</span></span></span><br><span class="line"><span class="function">    -解析</span></span><br><span class="line"><span class="function">    &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="function">             <span class="title">xpath</span>  </span></span><br><span class="line"><span class="function">             选择文本  /<span class="title">text</span>()</span></span><br><span class="line"><span class="function">             选择属性  /@<span class="title">href</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">             <span class="title">css</span></span></span><br><span class="line"><span class="function">             选择文本  :</span>:text</span><br><span class="line">             选择属性  ::attr(href)</span><br><span class="line"></span><br><span class="line">             <span class="comment"># extract_first取一个</span></span><br><span class="line">             <span class="comment"># extract()  取所有（列表形式）</span></span><br><span class="line"></span><br><span class="line">            <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">   -在解析的函数中yeild Request对象，这个地址又会去发请求</span></span><br><span class="line"><span class="string">		-yield Request(url=url,callback=self.parser_detail)</span></span><br><span class="line"><span class="string">   		-不写默认用yield Request(url=url,callback=self.parser)</span></span><br></pre></td></tr></table></figure>

<h2 id="5-scrapy持久化"><a href="#5-scrapy持久化" class="headerlink" title="5 scrapy持久化"></a>5 scrapy持久化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">- scrapy 持久化存储</span><br><span class="line">	-基于终端指令</span><br><span class="line">    	- scrapy crawl 爬虫名 -o filePath</span><br><span class="line">		- scrapy crawl cnblogs -o cnblogs.json []</span><br><span class="line">        - 好处：简洁高效便捷</span><br><span class="line">        - 坏处：局限性比较强（数据只可以存储到指定的文件夹后缀中）</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">- scrapy 持久化存储</span><br><span class="line">	- 基于管道</span><br><span class="line">    	- 编码流程：</span><br><span class="line">        	- 数据解析</span><br><span class="line">            - 将解析的数据存储到item类型的对象</span><br><span class="line">            - 将item类型的对象提交给管道（piplines）进行持久化存储的操作</span><br><span class="line">            - 在管道类的process_item中要将其接受到的item对象中存储的数据进行持久化存储操作</span><br><span class="line">            - 在配置文件中开启管道</span><br><span class="line">            </span><br><span class="line"></span><br><span class="line"><span class="number">1</span> 在items中写类，类中写字段</span><br><span class="line">      <span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpiderItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">          title = scrapy.Field()</span><br><span class="line">          desc=scrapy.Field()</span><br><span class="line">          url=scrapy.Field()</span><br><span class="line">          author=scrapy.Field()</span><br><span class="line">          <span class="comment"># 重点(文章详情，如果跟之前爬过的文章对应)</span></span><br><span class="line">          content=scrapy.Field()</span><br><span class="line"><span class="number">2</span> 在爬虫中把要保存的字段放到item对象中</span><br><span class="line">      article_item[<span class="string">&#x27;url&#x27;</span>]=url</span><br><span class="line">      article_item[<span class="string">&#x27;title&#x27;</span>]=title</span><br><span class="line">      article_item[<span class="string">&#x27;desc&#x27;</span>]=desc</span><br><span class="line">      article_item[<span class="string">&#x27;author&#x27;</span>]=author</span><br><span class="line">      <span class="keyword">yield</span> article_item	</span><br><span class="line"><span class="number">3</span> 在setting中配置</span><br><span class="line"></span><br><span class="line">      ITEM_PIPELINES = &#123;</span><br><span class="line">       <span class="string">&#x27;cnblogs_spider.pipelines.CnblogsSpiderFilePipeline&#x27;</span>: <span class="number">300</span>,  <span class="comment"># 数字表示优先级，数字越小，优先级越大</span></span><br><span class="line">       <span class="string">&#x27;cnblogs_spider.pipelines.CnblogsSpiderMysqlPipeline&#x27;</span>: <span class="number">400</span>,  <span class="comment"># 数字表示优先级，数字越小，优先级越大</span></span><br><span class="line">    	&#125;</span><br><span class="line">    </span><br><span class="line"><span class="number">4</span> 在pipline中写</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpiderFilePipeline</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;重写父类的一个方法：该方法只在开始爬虫的时候调用一次&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;spider是爬虫对象&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(spider.name)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫开始了&#x27;</span>)</span><br><span class="line">        self.f = <span class="built_in">open</span>(<span class="string">&#x27;cnblogs.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        self.f.write(item[<span class="string">&#x27;title&#x27;</span>] + item[<span class="string">&#x27;desc&#x27;</span>] + item[<span class="string">&#x27;author&#x27;</span>] + item[<span class="string">&#x27;url&#x27;</span>])</span><br><span class="line">        self.f.write(<span class="string">&#x27;/n&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;爬虫停止会执行&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫停止了&#x27;</span>)</span><br><span class="line">        self.f.close()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>爬虫的数据一份存到本地，一份存到数据库</strong></p>
<p>settings.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> ITEM_PIPELINES = &#123;</span><br><span class="line">  <span class="string">&#x27;cnblogs_spider.pipelines.CnblogsSpiderFilePipeline&#x27;</span>: <span class="number">300</span>,  <span class="comment"># 数字表示优先级，数字越小，优先级越大</span></span><br><span class="line">  <span class="string">&#x27;cnblogs_spider.pipelines.CnblogsSpiderMysqlPipeline&#x27;</span>: <span class="number">400</span>,  <span class="comment"># 数字表示优先级，数字越小，优先级越大</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpiderFilePipeline</span>:</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;重写父类的一个方法：该方法只在开始爬虫的时候调用一次&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;spider是爬虫对象&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(spider.name)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫开始了&#x27;</span>)</span><br><span class="line">        self.f = <span class="built_in">open</span>(<span class="string">&#x27;cnblogs.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        self.f.write(item[<span class="string">&#x27;title&#x27;</span>] + item[<span class="string">&#x27;desc&#x27;</span>] + item[<span class="string">&#x27;author&#x27;</span>] + item[<span class="string">&#x27;url&#x27;</span>])</span><br><span class="line">        self.f.write(<span class="string">&#x27;/n&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;爬虫停止会执行&quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫停止了&#x27;</span>)</span><br><span class="line">        self.f.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;管道文件中一个管道类对应将一组数据存储到一个平台或载体中&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpiderMysqlPipeline</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫开始了&#x27;</span>)</span><br><span class="line">        self.conn = pymysql.connect(host=<span class="string">&#x27;127.0.0.1&#x27;</span>, user=<span class="string">&#x27;root&#x27;</span>, password=<span class="string">&quot;1018&quot;</span>, database=<span class="string">&#x27;cnblogs&#x27;</span>, port=<span class="number">3306</span>)</span><br><span class="line">        self.cursor = self.conn.cursor()  <span class="comment"># 拿到游标</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span>(<span class="params">self, spider</span>):</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;爬虫结束了&#x27;</span>)</span><br><span class="line">        self.conn.commit()  <span class="comment"># 提交到数据库</span></span><br><span class="line">        self.cursor.close()  <span class="comment"># 关闭游标</span></span><br><span class="line">        self.conn.close()  <span class="comment"># 关闭链接</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span>(<span class="params">self, item, spider</span>):</span></span><br><span class="line">        sql = <span class="string">&#x27;insert into blog (title,`desc`,url,author,content) values (%s,%s,%s,%s,%s)&#x27;</span></span><br><span class="line">        self.cursor.execute(sql, args=[item[<span class="string">&#x27;title&#x27;</span>], item[<span class="string">&#x27;desc&#x27;</span>], item[<span class="string">&#x27;url&#x27;</span>], item[<span class="string">&#x27;author&#x27;</span>], item[<span class="string">&#x27;content&#x27;</span>]])</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 爬虫文件提交的item类型的对象最终会提交到哪个管道类？</span></span><br><span class="line">	- 根据优先级</span><br><span class="line">    - 只要在管道类<span class="function"><span class="keyword">def</span> <span class="title">process_item</span>中<span class="title">return</span> <span class="title">item</span> 就会传递给下一个将要执行的管道类</span></span><br></pre></td></tr></table></figure>

<h3 id="5-1-全站爬取"><a href="#5-1-全站爬取" class="headerlink" title="5.1 全站爬取"></a>5.1 全站爬取</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">- 基于spider的全站数据爬取</span><br><span class="line">- 实现方式：</span><br><span class="line">	- 将页面所有的url添加到start_urls(不推荐)</span><br><span class="line">    - 手动发送请求</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><img src="/2020/12/23/%E7%88%AC%E8%99%AB/image-20210806010100962.png" alt="爬虫">    </p>
<ul>
<li>手动发送请求</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> xiaohua.items <span class="keyword">import</span> XiaohuaItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XiaohuarSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;xiaohuar&#x27;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&#x27;xxx.com&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;http://www.521609.com/meinvxiaohua/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    url = <span class="string">&#x27;http://www.521609.com/meinvxiaohua/list12%d.html&#x27;</span></span><br><span class="line">    page_num = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        li_list = response.xpath(<span class="string">&#x27;//*[@id=&quot;content&quot;]/div[2]/div[2]/ul/li&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            img = <span class="string">&quot;http://www.521609.com/&quot;</span> + li.xpath(<span class="string">&#x27;./a/img/@src&#x27;</span>).extract_first()</span><br><span class="line">            <span class="built_in">print</span>(img)</span><br><span class="line">            item = XiaohuaItem()</span><br><span class="line">            item[<span class="string">&#x27;img&#x27;</span>] = img</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.page_num &lt;= <span class="number">2</span>:</span><br><span class="line">            new_url = <span class="built_in">format</span>(self.url % self.page_num)</span><br><span class="line">            self.page_num += <span class="number">1</span></span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=new_url, callback=self.parse)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<ul>
<li>自动发送请求</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="5-2-图片数据爬取之ImagesPipline"><a href="#5-2-图片数据爬取之ImagesPipline" class="headerlink" title="5.2 图片数据爬取之ImagesPipline"></a>5.2 图片数据爬取之ImagesPipline</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">- 基于Scrapy爬取字符串类型的数据和爬取图片类型的数据区别</span><br><span class="line">- 字符串：只需要基于xpath表达式进行解析且提交到管道进行持久化存储</span><br><span class="line">- Image：xpath解析出的图片src的属性值，单独对图片的地址发请求获取图片二进制数据类型</span><br><span class="line"></span><br><span class="line">- ImagesPipline</span><br><span class="line">	- 只需要将Image的src属性值解析，提交到管道，管道就会对图片的src进行请求发送获取图片的二进制数据</span><br><span class="line">    需求：爬取糗图</span><br><span class="line">    - 使用流程</span><br><span class="line">      - 数据解析（图片的地址）</span><br><span class="line">      - 将存储图片地址的item提交到制定的管道类</span><br><span class="line">      - 在管道文件中自定制一个基于imagesPipeline的一个管道类</span><br><span class="line">        -get_media_requests</span><br><span class="line">        -file_path</span><br><span class="line">        -item_completed</span><br><span class="line">      - 配置文件中</span><br><span class="line">    	- 指定下载图片的目录 IMAGES_STORE = <span class="string">&#x27;./imgs&#x27;</span>  <span class="comment"># 图片存储路径</span></span><br><span class="line">		- 开启自定制的管道类</span><br><span class="line">        ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;imagepro.pipelines.imagesPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>example.py</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> imagepro.items <span class="keyword">import</span> ImageproItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExampleSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;example&#x27;</span></span><br><span class="line">    <span class="comment"># allowed_domains = [&#x27;example.com&#x27;]</span></span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.qiushibaike.com/imgrank/&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span>(<span class="params">self, response</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;用作数据解析，response参数表示的是请求成功后对应的响应参数&quot;&quot;&quot;</span></span><br><span class="line">        div_list = response.xpath(<span class="string">&#x27;//*[@id=&quot;content&quot;]/div/div[2]&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> div <span class="keyword">in</span> div_list:</span><br><span class="line">            srcList = div.xpath(<span class="string">&#x27;./div/div[2]/a/img/@src&#x27;</span>).extract()</span><br><span class="line">            <span class="keyword">for</span> src <span class="keyword">in</span> srcList:</span><br><span class="line">                src = <span class="string">&#x27;https:&#x27;</span> + src</span><br><span class="line"></span><br><span class="line">                item = ImageproItem()</span><br><span class="line">                item[<span class="string">&#x27;src&#x27;</span>] = src</span><br><span class="line">                <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>

<p><strong>pipline.py</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.pipelines.images <span class="keyword">import</span> ImagesPipeline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">imagesPipeline</span>(<span class="params">ImagesPipeline</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;就是可以根据图片的地址进行图片数据请求&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_media_requests</span>(<span class="params">self, item, info</span>):</span></span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(item[<span class="string">&#x27;src&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="string">&quot;&quot;&quot;指定图片存储的路径&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">file_path</span>(<span class="params">self, request, response=<span class="literal">None</span>, info=<span class="literal">None</span>, *, item=<span class="literal">None</span></span>):</span></span><br><span class="line">        imgName = request.url.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">return</span> imgName</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">item_completed</span>(<span class="params">self, results, item, info</span>):</span></span><br><span class="line">        <span class="keyword">return</span> item  <span class="comment"># 返回给下一个即将执行的管道类</span></span><br></pre></td></tr></table></figure>

<p><strong>items.py</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ImageproItem</span>(<span class="params">scrapy.Item</span>):</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    <span class="comment"># name = scrapy.Field()</span></span><br><span class="line">    src = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h2 id="6-请求传递参数"><a href="#6-请求传递参数" class="headerlink" title="6 请求传递参数"></a>6 请求传递参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 给另一个请求传递参数，在响应中拿到（借助meta）</span><br><span class="line">		<span class="keyword">yield</span> Request(url=url,callback=self.parser_detail,meta=&#123;<span class="string">&#x27;item&#x27;</span>:article_item&#125;)</span><br><span class="line"><span class="number">2</span> 在解析方法中通过response对象获取</span><br><span class="line">	 item=response.meta.get(<span class="string">&#x27;item&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="7-提高爬虫效率"><a href="#7-提高爬虫效率" class="headerlink" title="7 提高爬虫效率"></a>7 提高爬虫效率</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 提高scrapy的爬取效率（异步框架，基于twisted，性能很高了，可以优化的点），面试聊</span><br><span class="line"></span><br><span class="line">- 在配置文件中进行相关的配置即可:(默认还有一套setting，类比django)</span><br><span class="line"><span class="comment">#1 增加并发：</span></span><br><span class="line">默认scrapy开启的并发线程为<span class="number">32</span>个，可以适当进行增加。在settings配置文件中修改CONCURRENT_REQUESTS = <span class="number">100</span>值为<span class="number">100</span>,并发设置成了为<span class="number">100</span>。</span><br><span class="line">CONCURRENT_REQUESTS = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#2 降低日志级别：</span></span><br><span class="line">在运行scrapy时，会有大量日志信息的输出，为了减少CPU的使用率。可以设置log输出信息为INFO或者ERROR即可。在配置文件中编写：LOG_LEVEL = ‘INFO’</span><br><span class="line"><span class="comment"># 3 禁止cookie：（cnblogs不需要cookie）</span></span><br><span class="line">如果不是真的需要cookie，则在scrapy爬取数据时可以禁止cookie从而减少CPU的使用率，提升爬取效率。在配置文件中编写：COOKIES_ENABLED = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 4禁止重试：</span></span><br><span class="line">对失败的HTTP进行重新请求（重试）会减慢爬取速度，因此可以禁止重试。在配置文件中编写：</span><br><span class="line">RETRY_ENABLED = <span class="literal">False</span></span><br><span class="line"><span class="comment"># 5 减少下载超时：</span></span><br><span class="line">如果对一个非常慢的链接进行爬取，减少下载超时可以能让卡住的链接快速被放弃，从而提升效率。在配置文件中进行编写：</span><br><span class="line">DOWNLOAD_TIMEOUT = <span class="number">10</span> 超时时间为10s</span><br><span class="line">	</span><br></pre></td></tr></table></figure>

<h2 id="8-scrapy中间件"><a href="#8-scrapy中间件" class="headerlink" title="8 scrapy中间件"></a>8 scrapy中间件</h2><h3 id="8-1-下载中间件CnblogsSpiderDownloaderMiddleware"><a href="#8-1-下载中间件CnblogsSpiderDownloaderMiddleware" class="headerlink" title="8.1 下载中间件CnblogsSpiderDownloaderMiddleware"></a>8.1 下载中间件CnblogsSpiderDownloaderMiddleware</h3><h4 id="process-request"><a href="#process-request" class="headerlink" title="process_request"></a>process_request</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 请求来的时候</span><br><span class="line">  <span class="comment"># Must either:</span></span><br><span class="line">  <span class="comment"># - return None: continue processing this request     返回None，进入下一个下载中间件的process_request</span></span><br><span class="line">  <span class="comment"># - or return a Response object                       返回response对象，会给引擎，引擎给爬虫，进入解析</span></span><br><span class="line">  <span class="comment"># - or return a Request object                        返回请求对象，会给引擎，引擎给调度器，放到调度器</span></span><br><span class="line">  <span class="comment"># - or raise IgnoreRequest: process_exception() methods of 抛异常，就会触发process_exception的执行</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 总结：</span></span><br><span class="line">  返回<span class="literal">None</span>，继续爬取</span><br><span class="line">  返回Resoponse对象，会给引擎，给爬虫，去解析</span><br><span class="line">  返回Request对象，会给引擎，给调度器，等待下一次被调度</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 什么情况会用它：</span></span><br><span class="line">  加代理，加cookie，加浏览器类型</span><br><span class="line">	集成 selenium</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 修改cookie</span></span><br><span class="line">  request.cookies=&#123;<span class="string">&#x27;name&#x27;</span>:<span class="string">&#x27;lqz&#x27;</span>&#125;</span><br><span class="line">  <span class="comment"># 使用代理</span></span><br><span class="line">  proxy=<span class="string">&#x27;http://154.16.63.16:8080&#x27;</span>  <span class="comment"># 从代理池中获取</span></span><br><span class="line">  request.meta[<span class="string">&quot;proxy&quot;</span>] =proxy</span><br><span class="line">  <span class="comment"># 修改请求头</span></span><br><span class="line">  request.headers.setlist(<span class="string">b&#x27;User-Agent&#x27;</span>,<span class="string">&#x27;asdfadsfadsf&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="process-response"><a href="#process-response" class="headerlink" title="process_response"></a>process_response</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Must either;</span></span><br><span class="line"><span class="comment"># - return a Response object        正常逻辑，给 引擎，引擎个爬虫去解析</span></span><br><span class="line"><span class="comment"># - return a Request object         返回Request对象，给引擎，引擎给调度器，等待下一次被调度</span></span><br><span class="line"><span class="comment"># - or raise IgnoreRequest          抛异常IgnoreRequest，响应不要了，不会给引擎，再给爬虫解析</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 总结</span></span><br><span class="line">返回Response,正常逻辑走</span><br><span class="line">返回Request，放到调度器</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 什么情况会用到</span></span><br><span class="line">抛异常，不再解析该响应（用的也不多）</span><br></pre></td></tr></table></figure>

<h2 id="9-集成selenium"><a href="#9-集成selenium" class="headerlink" title="9 集成selenium"></a>9 集成selenium</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 在爬虫中写</span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> selenium <span class="keyword">import</span> webdriver</span><br><span class="line"><span class="keyword">from</span> scrapy <span class="keyword">import</span> Request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BiliSpider</span>(<span class="params">scrapy.Spider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;bili&#x27;</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.bilibili.com&#x27;</span>]</span><br><span class="line">    start_urls = [<span class="string">&#x27;https://www.bilibili.com/v/dance/otaku/#/all/click/0/1/2021-01-28,2021-02-04&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    bro = webdriver.Edge(executable_path=<span class="string">&#x27;msedgedriver.exe&#x27;</span>)</span><br><span class="line">    bro.implicitly_wait(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close</span>(<span class="params">spider, reason</span>):</span></span><br><span class="line">        spider.bro.close()</span><br><span class="line"></span><br><span class="line">          </span><br><span class="line">          </span><br><span class="line"><span class="number">2</span> 在中间件中直接使用</span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpiderDownloaderMiddleware</span>:</span></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">process_request</span>(<span class="params">self, request, spider</span>):</span></span><br><span class="line">          spider.bro.get(request.url)</span><br><span class="line">          response=HtmlResponse(url=request.url,body=<span class="built_in">bytes</span>(spider.bro.page_source,encoding=<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">          <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>

<h2 id="10-去重规则"><a href="#10-去重规则" class="headerlink" title="10 去重规则"></a>10 去重规则</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 默认会去重，使用了</span><br><span class="line">	<span class="keyword">from</span> scrapy.dupefilters <span class="keyword">import</span> RFPDupeFilter</span><br><span class="line"><span class="number">2</span> 在默认的setting中配的</span><br><span class="line"><span class="number">3</span> 本身原理是使用的是集合去重</span><br><span class="line"></span><br><span class="line"><span class="number">4</span> 更高级部分</span><br><span class="line"><span class="comment"># 是不是同一个地址</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>/?name=lqz&amp;age=<span class="number">19</span></span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>/?age=<span class="number">19</span>&amp;name=lqz</span><br><span class="line"><span class="comment"># 本质原理，把?后的打散了，再排序</span></span><br><span class="line">fp = self.request_fingerprint(request) <span class="comment"># 得到一个指纹，上面那两个地址结果一样</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">## 自定义去重规则</span></span><br><span class="line">如果你自己写去重类，如何使用？</span><br><span class="line">写一个类，继承 BaseDupeFilter，重写<span class="function"><span class="keyword">def</span> <span class="title">request_seen</span>(<span class="params">self, request</span>):</span></span><br><span class="line">返回true表示爬过了</span><br><span class="line">返回false表示没有爬过</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 你有个更牛逼的去重方案</span></span><br><span class="line">	-集合去重可以，存在问题，如果地址特别多，上亿个地址，集合会特别大，会非常占用内存</span><br><span class="line">  -极小内存，完成去重（布隆过滤器）</span><br></pre></td></tr></table></figure>

<h2 id="11-分布式爬虫"><a href="#11-分布式爬虫" class="headerlink" title="11 分布式爬虫"></a>11 分布式爬虫</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> 借助于scrapy-redis</span><br><span class="line"></span><br><span class="line"><span class="number">2</span> 在scrapy的配置文件中修改</span><br><span class="line">  <span class="comment">#  把调度器替换成scrapy-redis的调度器</span></span><br><span class="line">  SCHEDULER = <span class="string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span></span><br><span class="line">  <span class="comment"># 去重规则，使用scrapy-redis写的类</span></span><br><span class="line">  DUPEFILTER_CLASS = <span class="string">&quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span></span><br><span class="line">  <span class="comment"># 爬取的起始地址的key</span></span><br><span class="line">  <span class="comment"># REDIS_START_URLS_KEY = &#x27;cnblogs:start_urls&#x27;</span></span><br><span class="line">  <span class="comment"># 不写就是连本地的6379</span></span><br><span class="line">  <span class="comment"># REDIS_HOST = &#x27;localhost&#x27;</span></span><br><span class="line">  <span class="comment"># REDIS_PORT = 6379</span></span><br><span class="line">  ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">&#x27;scrapy_redis.pipelines.RedisPipeline&#x27;</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="number">3</span> 修改爬虫</span><br><span class="line"><span class="keyword">from</span> scrapy_redis.spiders <span class="keyword">import</span> RedisSpider</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CnblogsSpider</span>(<span class="params">RedisSpider</span>):</span></span><br><span class="line">    name = <span class="string">&#x27;cnblogs_redis&#x27;</span>   <span class="comment"># 爬虫名字（不能重复）</span></span><br><span class="line">    allowed_domains = [<span class="string">&#x27;www.cnblogs.com&#x27;</span>] <span class="comment"># 允许的域（只爬取当前域下的地址）</span></span><br><span class="line">    redis_key = <span class="string">&#x27;myspider:start_urls&#x27;</span></span><br><span class="line">    </span><br><span class="line"><span class="number">4</span> 命令行切换到项目目录 D:\Scrapy&gt;scrapy crawl cnblogs_redis</span><br><span class="line"><span class="number">5</span> 部署在不同的机器上</span><br><span class="line">连接到redis上，设置起始地址</span><br><span class="line">lpush myspider:start_urls http://www.cnblogs.com</span><br></pre></td></tr></table></figure>

<h2 id="12-布隆过滤器"><a href="#12-布隆过滤器" class="headerlink" title="12 布隆过滤器"></a>12 布隆过滤器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="number">1</span> bloomfilter：是一个通过多哈希函数映射到一张表的数据结构，能够快速的判断一个元素在一个集合内是否存在，具有很好的空间和时间效率</span><br><span class="line"><span class="number">2</span> 数组：连续存储的内存空间：取值，改值效率高；；；插入值，删除值效率低</span><br><span class="line"><span class="number">3</span> 链表：不连续的内存空间，可变长：取值，改之效率低；；；插入删除效率高</span><br><span class="line"><span class="number">3</span> 你现在看到的所有数据结构，本质就是数字，字符串，布尔，数组，链表（列表，元组，字典，集合）</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="number">4</span> 计算机最小单位：比特位   <span class="number">8</span>个比特位是1byte</span><br><span class="line">  utf-<span class="number">8</span>： abcdefg-----<span class="number">7</span>个<span class="built_in">bytes</span>----》<span class="number">56</span>个比特位</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="number">5</span> python中使用布隆过滤器（不同语言中都会有）</span><br><span class="line">pip3 install pybloom_live</span><br><span class="line"><span class="comment"># from pybloom_live import ScalableBloomFilter</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># bloom = ScalableBloomFilter(initial_capacity=100, error_rate=0.00001, mode=ScalableBloomFilter.LARGE_SET_GROWTH)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># url = &quot;www.cnblogs.com&quot;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># url2 = &quot;www.liuqingzheng.top&quot;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># bloom.add(url)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># print(url in bloom)</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># print(url2 in bloom)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pybloom_live <span class="keyword">import</span> BloomFilter</span><br><span class="line"><span class="comment"># 10来个</span></span><br><span class="line">bf = BloomFilter(capacity=<span class="number">1000</span>)</span><br><span class="line">url=<span class="string">&#x27;www.baidu.com&#x27;</span></span><br><span class="line">bf.add(url)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(url <span class="keyword">in</span> bf)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;www.liuqingzheng.top&quot;</span> <span class="keyword">in</span> bf)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用redis的布隆过滤器</span></span><br><span class="line">使用方式见博客</span><br></pre></td></tr></table></figure>


    </div>

    
    
    
	  
	  
		   <div>
			 <div>
    
        <div style="text-align:center;color: #ccc;font-size:20px;">-------------End-------------</div>
    
</div>
		   </div>
	   

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%88%AC%E8%99%AB/" rel="tag"># 爬虫</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/12/10/luffy/" rel="prev" title="luffy">
      <i class="fa fa-chevron-left"></i> luffy
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/01/16/Vue/" rel="next" title="Vue">
      Vue <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%BC%82%E6%AD%A5%E7%88%AC%E8%99%AB"><span class="nav-number">1.</span> <span class="nav-text">异步爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-asyncio"><span class="nav-number">1.1.</span> <span class="nav-text">1 asyncio</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BC%82%E6%AD%A5"><span class="nav-number">1.2.</span> <span class="nav-text">2 多线程异步</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%BC%82%E6%AD%A5%E5%8D%8F%E7%A8%8B"><span class="nav-number">1.3.</span> <span class="nav-text">3 多任务异步协程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-%E7%A0%B4%E8%A7%A3%E9%AA%8C%E8%AF%81%E7%A0%81%E7%99%BB%E5%BD%95"><span class="nav-number">1.4.</span> <span class="nav-text">4 破解验证码登录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-http%E4%B8%8Ehttps%E5%8D%8F%E8%AE%AE"><span class="nav-number">1.5.</span> <span class="nav-text">5 http与https协议</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E4%BB%A3%E7%90%86%E6%93%8D%E4%BD%9C"><span class="nav-number">1.6.</span> <span class="nav-text">6 代理操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-re%E6%A8%A1%E5%9D%97%E5%AF%B9js%E4%BB%A3%E7%A0%81%E6%8C%87%E5%AE%9A%E8%BF%87%E6%BB%A4"><span class="nav-number">1.7.</span> <span class="nav-text">7 re模块对js代码指定过滤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-%E5%8D%95%E7%BA%BF%E7%A8%8B-%E5%BC%82%E6%AD%A5%E5%8D%8F%E7%A8%8B"><span class="nav-number">1.8.</span> <span class="nav-text">8 单线程+异步协程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-%E8%B6%85%E7%BA%A7%E9%B9%B0%E5%B9%B3%E5%8F%B0"><span class="nav-number">1.9.</span> <span class="nav-text">9 超级鹰平台</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#xpath%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%8F%90%E5%8F%96"><span class="nav-number">1.10.</span> <span class="nav-text">xpath表达式提取</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#aiohttp%E6%A8%A1%E5%9D%97"><span class="nav-number">2.</span> <span class="nav-text">aiohttp模块</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#requests%E6%A8%A1%E5%9D%97"><span class="nav-number">3.</span> <span class="nav-text">requests模块</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-get%E8%AF%B7%E6%B1%82"><span class="nav-number">3.1.</span> <span class="nav-text">1 get请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-post%E8%AF%B7%E6%B1%82"><span class="nav-number">3.2.</span> <span class="nav-text">2 post请求</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E5%8F%91%E9%80%81post%E8%AF%B7%E6%B1%82%E6%A8%A1%E6%8B%9F%E7%99%BB%E5%BD%95"><span class="nav-number">3.3.</span> <span class="nav-text">2.1 发送post请求模拟登录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%93%8D%E5%BA%94Response"><span class="nav-number">3.4.</span> <span class="nav-text">3 响应Response</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#selenium%E6%A8%A1%E5%9D%97"><span class="nav-number">4.</span> <span class="nav-text">selenium模块</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-selenium%E4%BB%8B%E7%BB%8D"><span class="nav-number">4.1.</span> <span class="nav-text">1 selenium介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-selenium%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="nav-number">4.2.</span> <span class="nav-text">2 selenium基本使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-selenium%E7%9A%84%E5%85%B6%E5%AE%83%E4%BD%BF%E7%94%A8"><span class="nav-number">4.3.</span> <span class="nav-text">3 selenium的其它使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-selenium-%E7%88%AC%E5%8F%96%E4%BA%AC%E4%B8%9C%E5%95%86%E5%93%81%E4%BF%A1%E6%81%AF"><span class="nav-number">4.4.</span> <span class="nav-text">4 selenium 爬取京东商品信息</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#scrapy%E6%A8%A1%E5%9D%97"><span class="nav-number">5.</span> <span class="nav-text">scrapy模块</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-%E5%AE%89%E8%A3%85"><span class="nav-number">5.1.</span> <span class="nav-text">1 安装</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#settings-py"><span class="nav-number">5.1.1.</span> <span class="nav-text">settings.py</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-%E6%9E%B6%E6%9E%84"><span class="nav-number">5.2.</span> <span class="nav-text">2 架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E7%9B%AE%E5%BD%95%E4%BB%8B%E7%BB%8D"><span class="nav-number">5.3.</span> <span class="nav-text">3 目录介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-scrapy%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8"><span class="nav-number">5.4.</span> <span class="nav-text">4 scrapy的简单使用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-scrapy%E6%8C%81%E4%B9%85%E5%8C%96"><span class="nav-number">5.5.</span> <span class="nav-text">5 scrapy持久化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-1-%E5%85%A8%E7%AB%99%E7%88%AC%E5%8F%96"><span class="nav-number">5.5.1.</span> <span class="nav-text">5.1 全站爬取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-2-%E5%9B%BE%E7%89%87%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96%E4%B9%8BImagesPipline"><span class="nav-number">5.5.2.</span> <span class="nav-text">5.2 图片数据爬取之ImagesPipline</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E8%AF%B7%E6%B1%82%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0"><span class="nav-number">5.6.</span> <span class="nav-text">6 请求传递参数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-%E6%8F%90%E9%AB%98%E7%88%AC%E8%99%AB%E6%95%88%E7%8E%87"><span class="nav-number">5.7.</span> <span class="nav-text">7 提高爬虫效率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-scrapy%E4%B8%AD%E9%97%B4%E4%BB%B6"><span class="nav-number">5.8.</span> <span class="nav-text">8 scrapy中间件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-%E4%B8%8B%E8%BD%BD%E4%B8%AD%E9%97%B4%E4%BB%B6CnblogsSpiderDownloaderMiddleware"><span class="nav-number">5.8.1.</span> <span class="nav-text">8.1 下载中间件CnblogsSpiderDownloaderMiddleware</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#process-request"><span class="nav-number">5.8.1.1.</span> <span class="nav-text">process_request</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#process-response"><span class="nav-number">5.8.1.2.</span> <span class="nav-text">process_response</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-%E9%9B%86%E6%88%90selenium"><span class="nav-number">5.9.</span> <span class="nav-text">9 集成selenium</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-%E5%8E%BB%E9%87%8D%E8%A7%84%E5%88%99"><span class="nav-number">5.10.</span> <span class="nav-text">10 去重规则</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11-%E5%88%86%E5%B8%83%E5%BC%8F%E7%88%AC%E8%99%AB"><span class="nav-number">5.11.</span> <span class="nav-text">11 分布式爬虫</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="nav-number">5.12.</span> <span class="nav-text">12 布隆过滤器</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Admin"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Admin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2021-07 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Admin</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>







    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 


<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共151.4k字</span>
</div>
        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
